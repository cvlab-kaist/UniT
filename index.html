<html>

<head>
    <meta charset="utf-8" />
    <title>UniT: Unified Diffusion Transformer for High-Fidelity Text-Aware Image Restoration</title>
    <meta
        content="UniT: Unified Diffusion Transformer for High-Fidelity Text-Aware Image Restoration"
        name="description" />
    <meta
        content="UniT: Unified Diffusion Transformer for High-Fidelity Text-Aware Image Restoration"
        property="og:title" />
    <meta
        content="UniT: Unified Diffusion Transformer for High-Fidelity Text-Aware Image Restoration"
        property="og:description" />
    <meta
        content="UniT: Unified Diffusion Transformer for High-Fidelity Text-Aware Image Restoration"
        property="twitter:title" />
    <meta
        content="UniT: Unified Diffusion Transformer for High-Fidelity Text-Aware Image Restoration"
        property="twitter:description" />
    <meta property="og:type" content="website" />
    <meta content="summary_large_image" name="twitter:card" />
    <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css"
        crossorigin="anonymous">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&family=Varela+Round&display=swap"
        rel="stylesheet">
    <link href="style.css?" rel="stylesheet" type="text/css" />

    <!-- üîé Added minimal CSS for click‚Äëto‚Äëzoom lightbox -->
    <style>
      /* make images clearly zoomable */
      img.zoomable { cursor: zoom-in; transition: transform .2s ease; }

      /* fullscreen overlay */
      .lightbox-overlay {
        position: fixed; inset: 0; display: none; align-items: center; justify-content: center;
        background: rgba(0,0,0,.9); z-index: 10000;
      }
      .lightbox-overlay.active { display: flex; }
      .lightbox-overlay img { max-width: 95vw; max-height: 95vh; box-shadow: 0 10px 40px rgba(0,0,0,.6); border-radius: 8px; }
      /* show zoom-out cursor while overlay is open */
      .lightbox-overlay, .lightbox-overlay * { cursor: zoom-out; }

      /* prevent background scroll when overlay is open */
      body.no-scroll { overflow: hidden; }

      .title-video {
          width: 100px;  
          height: 100px; 
          object-fit: cover; 
          object-position: center;
          border-radius: 50%;
          border: 2px solid #ccc;
      }
    </style>

    <!-- MathJax for LaTeX rendering -->
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$','$$'], ['\\[','\\]']]
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            },
            svg: { fontCache: 'global' }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" async></script>
</head>

<body>
    <header class="site-header">
        <div class="container">
            <nav class="main-nav">
                <ul class="nav-links">
                    <li><a href="#abstract">Overview</a></li>
                    <li><a href="#method">Method</a></li>
                    <li><a href="#qual-results">Qualitative Results</a></li>
                    <li><a href="#quant-results">Quantitative Results</a></li>
                    <li><a href="#ablation-studies">Ablation Studies</a></li>
                    <!-- <li><a href="#analysis">Analysis</a></li> -->
                    <li><a href="#citation">Citation</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <div class="hero-section">
        <div class="container">
            <div class="title-row">
                <h1 class="title" style="margin-bottom: 0.3rem;">
                    <span class="gradient-text">UniT</span>: Unified Diffusion Transformer for High-Fidelity<br>
                    Text-Aware Image Restoration
                </h1>
                <h2 class="subtitle" style="margin-top: 0;">
                    arXiv 2025
                </h2>
            </div>

            <div class="author-list">
                <div class="author-row">
                    <div class="author-col">
                        <a href="https://github.com/jinlovespho" target="_blank" class="author-text">Jin Hyeon Kim<sup>1</sup></a>
                    </div>
                    <div class="author-col">
                        <a href="#" target="_blank" class="author-text">Paul Hyunbin Cho<sup>1</sup></a>
                    </div>
                    <div class="author-col">
                        <a href="#" target="_blank" class="author-text">Claire Kim<sup>1</sup></a>
                    </div>
                </div>
                <div class="author-row">
                    <div class="author-col">
                        <a href="https://github.com/Min-Jaewon" target="_blank" class="author-text">Jaewon Min<sup>1</sup></a>
                    </div>
                    <div class="author-col">
                        <a href="https://github.com/babywhale03" target="_blank" class="author-text">Jaeeun Lee<sup>1</sup></a>
                    </div>
                    <div class="author-col">
                        <a href="#" target="_blank" class="author-text">Jihye Park<sup>2</sup></a>
                    </div>
                    <div class="author-col">
                        <a href="#" target="_blank" class="author-text">Yeji Choi<sup>1</sup></a>
                    </div>
                    <div class="author-col">
                        <a href="https://cvlab.kaist.ac.kr/" target="_blank" class="author-text">Seungryong Kim<sup>1&dagger;</sup></a>
                    </div>
                </div>
            </div>


            <div class="author-affiliations">
                <p><sup>1</sup> KAIST AI</p>
                <p><sup>2</sup> Samsung Electronics</p>
                <p><sup>&dagger;</sup> Corresponding author</p>
            </div>

            <div class="link-labels base-row">
                <div class="base-col icon-col"><a href="" target="_blank" class="link-block">
                        <i class="fa fas fa-file-text main-icon" style="font-size: 60px"></i>
                        <strong class="link-labels-text">Paper</strong>
                    </a></div>
                <div class="base-col icon-col"><a href="https://github.com/cvlab-kaist/UniT" class="link-block">
                        <i class="fa fa-github main-icon" style="font-size: 60px"></i>
                        <strong class="link-labels-text">Code</strong>
                    </a></div>
                <div class="base-col icon-col"><a href="#citation" class="link-block">
                        <i class="fa fa-graduation-cap main-icon" style="font-size: 60px"></i>
                        <strong class="link-labels-text">Citation</strong>
                    </a></div>
            </div>

        </div>
    </div>

    <main class="main-content">
        <div class="container">
            <div id="abstract" class="base-row section">
                <h2>Introducing UniT</h2>
                <p class="paragraph">
                    We present <Strong>UniT</Strong> (<Strong>U</Strong>nified Diffusion <Strong>T</Strong>ransformer), a unified text-aware image restoration framework that combines a Diffusion Transformer (DiT), a Vision‚ÄìLanguage Model (VLM), and a Text Spotting Module (TSM) to perform high-fidelity text-aware image restoration. In UniT, each component serves a distinct role. The VLM extracts textual content from degraded images to provide initial textual guidance. The TSM generates intermediate OCR predictions at each denoising timestep, allowing the VLM to iteratively correct potential textual errors. The DiT-based restoration module, with its strong representational capacity, fully leverages the textual guidance to achieve fine-grained text restoration while suppressing text hallucinations.
                </p>
            </div>
            <!-- <div class="image-container">
                <div class="image-content">
                    <img class="large-image" src="images/unit_teaser.png" alt="unit_teaser_img">
                </div>
            </div> -->
            <div class="image-container">
                <div class="image-content">
                    <img src="images/fig_unit_teaser copy 15.png" alt="unit_teaser_img"
                        style="width: 100%; max-width: none;">
                </div>
            </div>


            <!-- <section id="method" class="section">
                <h2>Method</h2>
                <div class="image-container">
                    <div class="image-content">
                        <img class="medium-image" src="images/fig_unit_teaser copy 15.png" alt="unit_teaser_img">
                    </div>
                </div>
                <p>
                    Our approach integrates a strong 2D tracking backbone with additional modules designed to leverage multi-view information. 
                    Specifically, we introduce a camera encoding module to inject geometric information and a cross view-attention module to aggregate complementary cues across viewpoints. This combination allows our model to achieve robust spatio-temporal consistency across multiple views.
                </p>
            </section> -->


            <section id="qual-results" class="section">
                <h2>Qualitative Results</h2>


                <h3>Text Restoration Results on SA-Text and Real-Text Benchmarks</h3>
                <p>
                    <!-- Our method consistently boosts MLLM performance on vision-centric tasks by aligning intermediate visual features with a strong vision encoder. Gains persist even with SigLIPv2, showing that regularizing visual representations benefits MLLMs beyond compensating for contrastive pretraining limits. -->
                    We present qualitative text restoration results on the SA-Text and Real-Text benchmarks. Despite severe degradations affecting readability and style, UniT leverages a rich visual-linguistic prior, guided by precise character-level OCR predictions, to provide accurate textual guidance to the DiT restoration module, effectively recovering the degraded text. In contrast, existing methods frequently fail and often produce hallucinated text.
                </p>


                <h3>SA-Text (Level 1)</h3>
                <div class="slideshow-container">
                    <div class="slideshow">
                        <div class="slide active">
                            <img src="images/fig_qual_satext_1_1.png" alt="Qualitative Result on SA-Text (Level 1)">
                        </div>
                        <div class="slide">
                            <img src="images/fig_qual_satext_1_2.png" alt="Qualitative Result on SA-Text (Level 1)">
                        </div>
                        <div class="slide">
                            <img src="images/fig_qual_satext_1_3.png" alt="Qualitative Result on SA-Text (Level 1)">
                        </div>
                        <div class="slide">
                            <img src="images/fig_qual_satext_1_4.png" alt="Qualitative Result on SA-Text (Level 1)">
                        </div>
                    </div>

                    <button class="slideshow-nav prev" onclick="changeSlide(-1)">‚ùÆ</button>
                    <button class="slideshow-nav next" onclick="changeSlide(1)">‚ùØ</button>
                </div>


                <h3>SA-Text (Level 2)</h3>
                <div class="slideshow-container">
                    <div class="slideshow">
                        <div class="slide active">
                            <img src="images/fig_qual_satext_2_1.png" alt="Qualitative Result on SA-Text (Level 2)">
                        </div>
                        <div class="slide">
                            <img src="images/fig_qual_satext_2_2.png" alt="Qualitative Result on SA-Text (Level 2)">
                        </div>
                        <div class="slide">
                            <img src="images/fig_qual_satext_2_3.png" alt="Qualitative Result on SA-Text (Level 2)">
                        </div>
                        <div class="slide">
                            <img src="images/fig_qual_satext_2_4.png" alt="Qualitative Result on SA-Text (Level 2)">
                        </div>
                    </div>

                    <button class="slideshow-nav prev" onclick="changeSlide(-1)">‚ùÆ</button>
                    <button class="slideshow-nav next" onclick="changeSlide(1)">‚ùØ</button>
                </div>


                <h3>SA-Text (Level 3)</h3>
                <div class="slideshow-container">
                    <div class="slideshow">
                        <div class="slide active">
                            <img src="images/fig_qual_satext_3_1.png" alt="Qualitative Result on SA-Text (Level 3)">
                        </div>
                        <div class="slide">
                            <img src="images/fig_qual_satext_3_2.png" alt="Qualitative Result on SA-Text (Level 3)">
                        </div>
                        <div class="slide">
                            <img src="images/fig_qual_satext_3_3.png" alt="Qualitative Result on SA-Text (Level 3)">
                        </div>
                        <div class="slide">
                            <img src="images/fig_qual_satext_3_4.png" alt="Qualitative Result on SA-Text (Level 3)">
                        </div>
                    </div>

                    <button class="slideshow-nav prev" onclick="changeSlide(-1)">‚ùÆ</button>
                    <button class="slideshow-nav next" onclick="changeSlide(1)">‚ùØ</button>
                </div>


                <h3>Real-Text</h3>
                <div class="slideshow-container">
                    <div class="slideshow">
                        <div class="slide active">
                            <img src="images/fig_qual_realtext_1.png" alt="Qualitative Result on Real-Text">
                        </div>
                        <div class="slide">
                            <img src="images/fig_qual_realtext_2.png" alt="Qualitative Result on Real-Text">
                        </div>
                        <div class="slide">
                            <img src="images/fig_qual_realtext_3.png" alt="Qualitative Result on Real-Text">
                        </div>
                        <div class="slide">
                            <img src="images/fig_qual_realtext_4.png" alt="Qualitative Result on Real-Text">
                        </div>
                    </div>

                    <button class="slideshow-nav prev" onclick="changeSlide(-1)">‚ùÆ</button>
                    <button class="slideshow-nav next" onclick="changeSlide(1)">‚ùØ</button>
                </div>

            </section>

            
            
            <section id="quant-results" class="section">
                <h2>Quantitative Results</h2>
                
                <h3>SOTA End-to-End F1-Score Performance in TAIR</h3>
                <p>
                    <!-- Our method consistently boosts MLLM performance on vision-centric tasks by aligning intermediate visual features with a strong vision encoder. Gains persist even with SigLIPv2, showing that regularizing visual representations benefits MLLMs beyond compensating for contrastive pretraining limits. -->
                    We compare our approaches with recent state-of-the art point trackers on DexYCB, Panoptic Studio, Kubric and Harmony4D dataset.
                    Compared to baselines, MV-TAP achieves superior performance, demonstrating its ability to leverage multi-view information.
                </p>
                <div class="table-container">
                    <table class="advantages-table">
                        <thead>
                            <tr>
                                <th class="model-col" rowspan="2">Method</th>
                                <th class="left-bold-border-col" rowspan="2">Target</th>
                                <th class="model-col" rowspan="2">Space</th>
                                <th class="depth-col" rowspan="2">Depth</th>
                                <th colspan="3" class="left-bold-border-col">DexYCB</th>
                                <th colspan="3" class="left-bold-border-col">Panoptic Studio</th>
                                <th colspan="3" class="left-bold-border-col">Harmony4D</th>
                            </tr>
                            <tr>
                                <th class="left-bold-border-col">AJ</th>
                                <th>&lt;$\delta_{avg}^x$</th>
                                <th>OA</th>
                                <th class="left-bold-border-col">AJ</th>
                                <th>&lt;$\delta_{avg}^x$</th>
                                <th>OA</th>
                                <th class="left-bold-border-col">AJ</th>
                                <th>&lt;$\delta_{avg}^x$</th>
                                <th>OA</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td colspan="16" class="category-row" style="color: gray; font-style: italic;">Single-view input</td>
                            </tr>
                            <tr>
                                <td class="model-col">TAPIR</td>
                                <td class="left-border-col">2D</td>
                                <td class="model-col">Camera</td>
                                <td class="depth-col"><i class="fa fa-times depth-no" aria-label="depth off"></i></td>
                                <td class="left-border-col">29.6</td>
                                <td>43.9</td>
                                <td>66.4</td>
                                <td class="left-border-col">22.1</td>
                                <td>39.3</td>
                                <td>60.0</td>
                                <td class="left-border-col">27.6</td>
                                <td>53.1</td>
                                <td>60.0</td>
                            </tr>
                            <tr>
                                <td class="model-col">CoTracker2</td>
                                <td class="left-border-col">2D</td>
                                <td class="model-col">Camera</td>
                                <td class="depth-col"><i class="fa fa-times depth-no" aria-label="depth off"></i></td>
                                <td class="left-border-col">37.5</td>
                                <td><strong>62.5</strong></td>
                                <td>69.4</td>
                                <td class="left-border-col">33.3</td>
                                <td>59.1</td>
                                <td>64.4</td>
                                <td class="left-border-col">37.2</td>
                                <td>71.9</td>
                                <td>55.7</td>
                            </tr>
                            <tr>
                                <td class="model-col">LocoTrack</td>
                                <td class="left-border-col">2D</td>
                                <td class="model-col">Camera</td>
                                <td class="depth-col"><i class="fa fa-times depth-no" aria-label="depth off"></i></td>
                                <td class="left-border-col">38.7</td>
                                <td>55.8</td>
                                <td>74.1</td>
                                <td class="left-border-col">34.9</td>
                                <td>56.1</td>
                                <td>67.5</td>
                                <td class="left-border-col">40.8</td>
                                <td>72.0</td>
                                <td><u>64.1</u></td>
                            </tr>
                            <tr>
                                <td class="model-col">CoTracker3</td>
                                <td class="left-border-col">2D</td>
                                <td class="model-col">Camera</td>
                                <td class="depth-col"><i class="fa fa-times depth-no" aria-label="depth off"></i></td>
                                <td class="left-border-col"><u>41.5</u></td>
                                <td>59.6</td>
                                <td><u>76.4</u></td>
                                <td class="left-border-col"><u>39.6</u></td>
                                <td>61.4</td>
                                <td><u>72.3</u></td>
                                <td class="left-border-col"><u>41.4</u></td>
                                <td><u>73.5</u></td>
                                <td>63.2</td>
                            </tr>
                            <tr>
                                <td class="model-col">SpatialTracker</td>
                                <td class="left-border-col">3D</td>
                                <td class="model-col">Camera</td>
                                <td class="depth-col"><i class="fa fa-check depth-yes" aria-label="depth on"></i></td>
                                <td class="left-border-col">23.2</td>
                                <td>43.3</td>
                                <td>61.8</td>
                                <td class="left-border-col">19.7</td>
                                <td>40.5</td>
                                <td>59.6</td>
                                <td class="left-border-col">25.4</td>
                                <td>54.4</td>
                                <td>58.1</td>
                            </tr>
                            <tr>
                                <td colspan="16" class="category-row" style="color: gray; font-style: italic;">Multi-view input</td>
                            </tr>
                            <tr>
                                <td class="model-col">CoTracker3<br>w/ Flat.</td>
                                <td class="left-border-col">2D</td>
                                <td class="model-col">Camera</td>
                                <td class="depth-col"><i class="fa fa-times depth-no" aria-label="depth off"></i></td>
                                <td class="left-border-col">2.7</td>
                                <td>7.1</td>
                                <td>35.7</td>
                                <td class="left-border-col">1.0</td>
                                <td>12.7</td>
                                <td>38.8</td>
                                <td class="left-border-col">2.1</td>
                                <td>20.7</td>
                                <td>46.4</td>
                            </tr>
                            <tr>
                                <td class="model-col">CoTracker3<br>w/ Tri.</td>
                                <td class="left-border-col">2D</td>
                                <td class="model-col">Camera</td>
                                <td class="depth-col"><i class="fa fa-times depth-no" aria-label="depth off"></i></td>
                                <td class="left-border-col">39.2</td>
                                <td>57.1</td>
                                <td><u>76.4</u></td>
                                <td class="left-border-col">37.9</td>
                                <td>59.5</td>
                                <td><u>72.3</u></td>
                                <td class="left-border-col">39.2</td>
                                <td>70.4</td>
                                <td>63.2</td>
                            </tr>
                            <tr>
                                <td class="model-col">MVTracker</td>
                                <td class="left-border-col">3D</td>
                                <td class="model-col">World</td>
                                <td class="depth-col"><i class="fa fa-check depth-yes" aria-label="depth on"></i></td>
                                <td class="left-border-col">-</td>
                                <td>32.6</td>
                                <td>-</td>
                                <td class="left-border-col">-</td>
                                <td><u>62.4</u></td>
                                <td>-</td>
                                <td class="left-border-col">-</td>
                                <td>13.3</td>
                                <td>-</td>
                            </tr>
                            <tr style="background-color: #f0f0f0;">
                                <td class="model-col"><strong>MV-TAP (Ours)</strong></td>
                                <td class="left-border-col">2D</td>
                                <td class="model-col">Camera</td>
                                <td class="depth-col"><i class="fa fa-times depth-no" aria-label="depth off"></i></td>
                                <td class="left-border-col"><strong>44.2</strong></td>
                                <td><u>61.9</u></td>
                                <td><strong>78.3</strong></td>
                                <td class="left-border-col"><strong>40.3</strong></td>
                                <td><strong>62.8</strong></td>
                                <td><strong>73.1</strong></td>
                                <td class="left-border-col"><strong>42.6</strong></td>
                                <td><strong>74.9</strong></td>
                                <td><strong>65.8</strong></td>
                            </tr>
                        </tbody>
                    </table>
                    <p class="image-caption">
                        'Target' denotes the dimension of the predicted trajectory. 
                        'Space' specifies the coordinate domain: 'Camera' and 'World' denotes pixel and world space, respectively. 
                        'Depth' indicates whether depth input is required. 
                    </p>
                </div>
            </section>


            <section id="ablation-studies" class="section">
                <h2>Ablation studies</h2>

                <h3>Ablation on various number of views</h3>
                <p>
                    We compare MV-TAP with baselines using a varying number of input views. While performance generally improves with more views, the baselines exhibit only marginal gains. In contrast, MV-TAP demonstrates a significantly larger improvement consistently, highlighting its superior ability to leverage multi-view information.
                </p>
                <div class="table-container">
                    <table class="advantages-table">
                        <thead>
                            <tr>
                                <th class="model-col" rowspan="2">Method</th>
                                <th colspan="3" class="left-bold-border-col">2 views</th>
                                <th colspan="3" class="left-bold-border-col">4 views</th>
                                <th colspan="3" class="left-bold-border-col">6 views</th>
                                <th colspan="3" class="left-bold-border-col">8 views</th>
                            </tr>
                            <tr>
                                <th class="left-bold-border-col">AJ</th>
                                <th>&lt;$\delta^{x}_{avg}$</th>
                                <th>OA</th>
                                <th class="left-bold-border-col">AJ</th>
                                <th>&lt;$\delta^{x}_{avg}$</th>
                                <th>OA</th>
                                <th class="left-bold-border-col">AJ</th>
                                <th>&lt;$\delta^{x}_{avg}$</th>
                                <th>OA</th>
                                <th class="left-bold-border-col">AJ</th>
                                <th>&lt;$\delta^{x}_{avg}$</th>
                                <th>OA</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td class="model-col">CoTracker3</td>
                                <td class="left-border-col"><u>37.5</u></td>
                                <td><u>56.4</u></td>
                                <td><strong>77.8</strong></td>
                                <td class="left-border-col"><u>38.9</u></td>
                                <td><u>56.6</u></td>
                                <td><u>75.1</u></td>
                                <td class="left-border-col"><u>41.0</u></td>
                                <td><u>58.9</u></td>
                                <td><u>75.8</u></td>
                                <td class="left-border-col"><u>41.5</u></td>
                                <td><u>59.6</u></td>
                                <td><u>76.4</u></td>
                            </tr>
                            <tr>
                                <td class="model-col">CoTracker3<br>w/ Flat.</td>
                                <td class="left-border-col">9.5</td>
                                <td>19.5</td>
                                <td>54.3</td>
                                <td class="left-border-col">4.4</td>
                                <td>8.4</td>
                                <td>44.5</td>
                                <td class="left-border-col">3.2</td>
                                <td>8.3</td>
                                <td>39.1</td>
                                <td class="left-border-col">2.7</td>
                                <td>7.1</td>
                                <td>35.7</td>
                            </tr>
                            <tr>
                                <td class="model-col">CoTracker3<br>w/ Tri.</td>
                                <td class="left-border-col">37.1</td>
                                <td>55.6</td>
                                <td><strong>77.8</strong></td>
                                <td class="left-border-col">37.8</td>
                                <td>55.3</td>
                                <td><u>75.1</u></td>
                                <td class="left-border-col">38.7</td>
                                <td>56.4</td>
                                <td><u>75.8</u></td>
                                <td class="left-border-col">39.2</td>
                                <td>57.1</td>
                                <td><u>76.4</u></td>
                            </tr>
                            <tr>
                                <td class="model-col">MVTracker</td>
                                <td class="left-border-col">-</td>
                                <td>35.8</td>
                                <td>-</td>
                                <td class="left-border-col">-</td>
                                <td>31.8</td>
                                <td>-</td>
                                <td class="left-border-col">-</td>
                                <td>32.8</td>
                                <td>-</td>
                                <td class="left-border-col">-</td>
                                <td>32.6</td>
                                <td>-</td>
                            </tr>
                            <tr style="background-color: #f0f0f0;">
                                <td class="model-col"><strong>MV-TAP (Ours)</strong></td>
                                <td class="left-border-col"><strong>39.2</strong></td>
                                <td><strong>56.8</strong></td>
                                <td><u>76.8</u></td>
                                <td class="left-border-col"><strong>40.3</strong></td>
                                <td><strong>57.7</strong></td>
                                <td><strong>75.2</strong></td>
                                <td class="left-border-col"><strong>43.3</strong></td>
                                <td><strong>60.7</strong></td>
                                <td><strong>76.9</strong></td>
                                <td class="left-border-col"><strong>44.2</strong></td>
                                <td><strong>61.9</strong></td>
                                <td><strong>78.3</strong></td>
                            </tr>
                        </tbody>
                    </table>
                    <!-- <p class="image-caption">‚ùóÔ∏èCAPTION NEEDED‚ùóÔ∏è</p> -->
                </div>

                <h3>Can multi-view resolve occlusion ambiguity?</h3>
                <p>
                    We also evaluate the position accuracy on in-frame occluded points. Our model shows robustness on the occlusion, indicating that our model effectively utilizes the multi-view cues. $<\delta^{x}_{occ}$ denotes point accuracy on in-frame occlusion points.
                </p>
                <div class="table-container">
                    <table class="advantages-table">
                        <thead>
                            <tr>
                                <th class="model-col" rowspan="2">Method</th>
                                <th colspan="2" class="left-bold-border-col">DexYCB</th>
                                <th colspan="2" class="left-bold-border-col">Panoptic Studio</th>
                                <th colspan="2" class="left-bold-border-col">Harmony4D</th>
                            </tr>
                            <tr>
                                <th class="left-bold-border-col">&lt;$\delta^{x}_{avg}$</th>
                                <th>&lt;$\delta^{x}_{occ}$</th>
                                <th class="left-bold-border-col">&lt;$\delta^{x}_{avg}$</th>
                                <th>&lt;$\delta^{x}_{occ}$</th>
                                <th class="left-bold-border-col">&lt;$\delta^{x}_{avg}$</th>
                                <th>&lt;$\delta^{x}_{occ}$</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td class="model-col">CoTracker3</td>
                                <td class="left-border-col"><u>59.6</u></td>
                                <td>33.9</td>
                                <td class="left-border-col">61.4</td>
                                <td>46.2</td>
                                <td class="left-border-col"><u>73.5</u></td>
                                <td>58.4</td>
                            </tr>
                            <tr>
                                <td class="model-col">CoTracker3<br>w/ Flat.</td>
                                <td class="left-border-col">7.1</td>
                                <td>1.9</td>
                                <td class="left-border-col">12.7</td>
                                <td>6.3</td>
                                <td class="left-border-col">20.7</td>
                                <td>15.0</td>
                            </tr>
                            <tr>
                                <td class="model-col">CoTracker3<br>w/ Tri.</td>
                                <td class="left-border-col">57.1</td>
                                <td>34.8</td>
                                <td class="left-border-col">59.5</td>
                                <td>47.7</td>
                                <td class="left-border-col">70.4</td>
                                <td><u>59.1</u></td>
                            </tr>
                            <tr>
                                <td class="model-col">MVTracker</td>
                                <td class="left-border-col">32.6</td>
                                <td>16.0</td>
                                <td class="left-border-col"><u>62.4</u></td>
                                <td><strong>61.2</strong></td>
                                <td class="left-border-col">13.3</td>
                                <td>8.9</td>
                            </tr>
                            <tr style="background-color: #f0f0f0;">
                                <td class="model-col"><strong>MV-TAP (Ours)</strong></td>
                                <td class="left-border-col"><strong>61.9</strong></td>
                                <td><strong>38.4</strong></td>
                                <td class="left-border-col"><strong>62.8</strong></td>
                                <td><u>48.7</u></td>
                                <td class="left-border-col"><strong>74.9</strong></td>
                                <td><strong>60.3</strong></td>
                            </tr>
                        </tbody>
                    </table>
                    <!-- <p class="image-caption">‚ùóÔ∏èCAPTION NEEDED‚ùóÔ∏è</p> -->
                </div>

                <h3>Effect of additional training</h3>
                <p>
                    Although initialized from the same pretrained model, MV-TAP attains consistently higher performance across all metrics. This shows that its gains primarily come from the architectural design, not merely extended training.
                </p>
                <div class="table-container">
                    <table class="advantages-table">
                        <thead>
                            <tr>
                                <th class="model-col" rowspan="2">Method</th>
                                <th colspan="3" class="left-bold-border-col">DexYCB</th>
                                <th colspan="3" class="left-bold-border-col">Panoptic Studio</th>
                            </tr>
                            <tr>
                                <th class="left-bold-border-col">AJ</th>
                                <th>&lt;$\delta^{x}_{avg}$</th>
                                <th>OA</th>
                                <th class="left-bold-border-col">AJ</th>
                                <th>&lt;$\delta^{x}_{avg}$</th>
                                <th>OA</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td class="model-col">CoTracker3</td>
                                <td class="left-border-col"><u>41.8</u></td>
                                <td><u>59.0</u></td>
                                <td><u>73.8</u></td>
                                <td class="left-border-col"><u>39.6</u></td>
                                <td><u>61.6</u></td>
                                <td><u>71.8</u></td>
                            </tr>
                            <tr style="background-color: #f0f0f0;">
                                <td class="model-col"><strong>MV-TAP (Ours)</strong></td>
                                <td class="left-border-col"><strong>44.2</strong></td>
                                <td><strong>61.9</strong></td>
                                <td><strong>78.3</strong></td>
                                <td class="left-border-col"><strong>40.3</strong></td>
                                <td><strong>62.8</strong></td>
                                <td><strong>73.1</strong></td>
                            </tr>
                        </tbody>
                    </table>
                    <!-- <p class="image-caption">‚ùóÔ∏èCAPTION NEEDED‚ùóÔ∏è</p> -->
                </div>

                <h3>Comparison on various number of points</h3>
                <p>
                    We measure tracking performances under varying numbers of query points. Our model consistently outperforms shows better robustness compared to the baselines across both sparse and dense settings.
                </p>
                <div class="table-container">
                    <table class="advantages-table">
                        <thead>
                            <tr>
                                <th class="model-col" rowspan="2">Method</th>
                                <th colspan="3" class="left-bold-border-col">50 Points</th>
                                <th colspan="3" class="left-bold-border-col">100 Points</th>
                                <th colspan="3" class="left-bold-border-col">300 Points</th>
                                <th colspan="3" class="left-bold-border-col">500 Points</th>
                            </tr>
                            <tr>
                                <th class="left-bold-border-col">AJ</th>
                                <th>&lt;$\delta^{x}_{avg}$</th>
                                <th>OA</th>
                                <th class="left-bold-border-col">AJ</th>
                                <th>&lt;$\delta^{x}_{avg}$</th>
                                <th>OA</th>
                                <th class="left-bold-border-col">AJ</th>
                                <th>&lt;$\delta^{x}_{avg}$</th>
                                <th>OA</th>
                                <th class="left-bold-border-col">AJ</th>
                                <th>&lt;$\delta^{x}_{avg}$</th>
                                <th>OA</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td class="model-col">CoTracker3</td>
                                <td class="left-border-col"><u>42.0</u></td>
                                <td><u>59.9</u></td>
                                <td><u>74.6</u></td>
                                <td class="left-border-col"><u>41.9</u></td>
                                <td><u>60.1</u></td>
                                <td><u>77.2</u></td>
                                <td class="left-border-col"><u>41.5</u></td>
                                <td><u>59.6</u></td>
                                <td><u>76.4</u></td>
                                <td class="left-border-col"><u>41.5</u></td>
                                <td><u>59.8</u></td>
                                <td><u>76.7</u></td>
                            </tr>
                            <tr>
                                <td class="model-col">CoTracker3<br>w/ Flat.</td>
                                <td class="left-border-col">2.7</td>
                                <td>7.4</td>
                                <td>34.4</td>
                                <td class="left-border-col">2.5</td>
                                <td>6.8</td>
                                <td>35.6</td>
                                <td class="left-border-col">2.7</td>
                                <td>7.1</td>
                                <td>35.7</td>
                                <td class="left-border-col">2.6</td>
                                <td>7.0</td>
                                <td>35.7</td>
                            </tr>
                            <tr>
                                <td class="model-col">CoTracker3<br>w/ Tri.</td>
                                <td class="left-border-col">39.4</td>
                                <td>53.4</td>
                                <td><u>74.6</u></td>
                                <td class="left-border-col">39.4</td>
                                <td>57.1</td>
                                <td><u>77.2</u></td>
                                <td class="left-border-col">39.2</td>
                                <td>57.1</td>
                                <td><u>76.4</u></td>
                                <td class="left-border-col">39.5</td>
                                <td>57.3</td>
                                <td><u>76.7</u></td>
                            </tr>
                            <tr>
                                <td class="model-col">MVTracker</td>
                                <td class="left-border-col">-</td>
                                <td>34.2</td>
                                <td>-</td>
                                <td class="left-border-col">-</td>
                                <td>32.9</td>
                                <td>-</td>
                                <td class="left-border-col">-</td>
                                <td>32.6</td>
                                <td>-</td>
                                <td class="left-border-col">-</td>
                                <td>34.9</td>
                                <td>-</td>
                            </tr>
                            <tr style="background-color: #f0f0f0;">
                                <td class="model-col"><strong>MV-TAP (Ours)</strong></td>
                                <td class="left-border-col"><strong>44.3</strong></td>
                                <td><strong>62.0</strong></td>
                                <td><strong>77.5</strong></td>
                                <td class="left-border-col"><strong>44.7</strong></td>
                                <td><strong>62.5</strong></td>
                                <td><strong>78.3</strong></td>
                                <td class="left-border-col"><strong>44.2</strong></td>
                                <td><strong>61.9</strong></td>
                                <td><strong>78.3</strong></td>
                                <td class="left-border-col"><strong>44.3</strong></td>
                                <td><strong>62.1</strong></td>
                                <td><strong>78.7</strong></td>
                            </tr>
                        </tbody>
                    </table>
                    <!-- <p class="image-caption">‚ùóÔ∏èCAPTION NEEDED‚ùóÔ∏è</p> -->
                </div>

                <h3>Ablation on model architecture</h3>
                <p>
                    We present an ablation study on our model components for multi-view awareness. The performance consistently improves as each component is added, demonstrating that each module significantly contributes to leveraging multi-view information.
                </p>
                <div class="table-container">
                    <table class="advantages-table">
                        <thead>
                            <tr>
                                <th class="model-col" rowspan="2">Method</th>
                                <th colspan="3" class="left-bold-border-col">DexYCB</th>
                                <th colspan="3" class="left-bold-border-col">Panoptic Studio</th>
                            </tr>
                            <tr>
                                <th class="left-bold-border-col">AJ</th>
                                <th>&lt;$\delta_{avg}^x$</th>
                                <th>OA</th>
                                <th class="left-bold-border-col">AJ</th>
                                <th>&lt;$\delta_{avg}^x$</th>
                                <th>OA</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td class="model-col">CoTracker3</td>
                                <td class="left-border-col">41.5</td>
                                <td>59.6</td>
                                <td>76.4</td>
                                <td class="left-border-col">39.6</td>
                                <td>61.4</td>
                                <td>72.3</td>
                            </tr>
                            <tr>
                                <td class="model-col">+ View attn.</td>
                                <td class="left-border-col"><u>43.6</u></td>
                                <td><u>61.5</u></td>
                                <td>77.4</td>
                                <td class="left-border-col">38.6</td>
                                <td><u>61.6</u></td>
                                <td>69.4</td>
                            </tr>
                            <tr>
                                <td class="model-col">+ Cam embed.</td>
                                <td class="left-border-col">42.2</td>
                                <td>60.6</td>
                                <td><u>78.0</u></td>
                                <td class="left-border-col"><u>39.9</u></td>
                                <td>60.9</td>
                                <td><u>73.0</u></td>
                            </tr>
                            <tr style="background-color: #f0f0f0;">
                                <td class="model-col"><strong>MV-TAP (Ours)</strong></td>
                                <td class="left-border-col"><strong>44.2</strong></td>
                                <td><strong>61.9</strong></td>
                                <td><strong>78.3</strong></td>
                                <td class="left-border-col"><strong>40.3</strong></td>
                                <td><strong>62.8</strong></td>
                                <td><strong>73.1</strong></td>
                            </tr>
                        </tbody>
                    </table>
                    <!-- <p class="image-caption">‚ùóÔ∏èCAPTION NEEDED‚ùóÔ∏è</p> -->
                </div>

                <h3>Comparison under frequently occluded trajectories</h3>
                <p>
                    We evaluate methods on trajectories with high occlusion frequency measured by visibility-transition rate. MV-TAP leverages cross-view cues to remain robust on frequently occluded points, improving AJ, $\delta^{x}_{\text{avg}}$ and OA.
                </p>
                <div class="table-container">
                    <table class="advantages-table">
                        <thead>
                            <tr>
                                <th class="model-col" rowspan="2">Method</th>
                                <th colspan="3" class="left-bold-border-col">DexYCB</th>
                                <th colspan="3" class="left-bold-border-col">Panoptic Studio</th>
                            </tr>
                            <tr>
                                <th class="left-bold-border-col">AJ</th>
                                <th>&lt;$\delta^{x}_{avg}$</th>
                                <th>OA</th>
                                <th class="left-bold-border-col">AJ</th>
                                <th>&lt;$\delta^{x}_{avg}$</th>
                                <th>OA</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td class="model-col">CoTracker3</td>
                                <td class="left-border-col"><u>26.2</u></td>
                                <td>43.4</td>
                                <td><u>66.6</u></td>
                                <td class="left-border-col"><u>37.4</u></td>
                                <td><u>60.6</u></td>
                                <td><u>69.0</u></td>
                            </tr>
                            <tr>
                                <td class="model-col">CoTracker3<br>w/ Flat.</td>
                                <td class="left-border-col">0.5</td>
                                <td>1.8</td>
                                <td>41.2</td>
                                <td class="left-border-col">0.8</td>
                                <td>13.4</td>
                                <td>40.6</td>
                            </tr>
                            <tr>
                                <td class="model-col">CoTracker3<br>w/ Tri.</td>
                                <td class="left-border-col">26.0</td>
                                <td><u>43.6</u></td>
                                <td><u>66.6</u></td>
                                <td class="left-border-col">36.6</td>
                                <td>59.4</td>
                                <td><u>69.0</u></td>
                            </tr>
                            <tr>
                                <td class="model-col">MVTracker</td>
                                <td class="left-border-col">-</td>
                                <td>7.9</td>
                                <td>-</td>
                                <td class="left-border-col">-</td>
                                <td>59.4</td>
                                <td>-</td>
                            </tr>
                            <tr style="background-color: #f0f0f0;">
                                <td class="model-col"><strong>MV-TAP (Ours)</strong></td>
                                <td class="left-border-col"><strong>29.7</strong></td>
                                <td><strong>47.3</strong></td>
                                <td><strong>70.5</strong></td>
                                <td class="left-border-col"><strong>38.0</strong></td>
                                <td><strong>61.9</strong></td>
                                <td><strong>69.9</strong></td>
                            </tr>
                        </tbody>
                    </table>
                    <!-- <p class="image-caption">‚ùóÔ∏èCAPTION NEEDED‚ùóÔ∏è</p> -->
                </div>
            </section>


            <section id="conclusion" class="section">
                <h2>Conclusion</h2>

                <p>This work establishes multi-view 2D point tracking as a new and important task for advancing reliable spatio-temporal correspondence in dynamic, real-world scenes. By introducing MV-TAP, a model that aggregates cross-view information through camera embedding and view-attention, we demonstrate how leveraging multi-view inputs can overcome key limitations of monocular trackers such as occlusion and motion ambiguity. Together with a large-scale synthetic dataset and a real-world evaluation dataset specifically designed for this task, our contributions provide both a principled formulation of the problem and a strong baseline method, paving the way for future research in robust multi-view point tracking.</p>
            </section>

            <div class="citation add-top-padding">
                <h1 id="citation">Citation</h1>
                <p> If you use this work or find it helpful, please consider citing: </p>
                <pre id="codecell0">
    @article{kim2025unit,
      title={UniT: Unified Diffusion Transformer for High-Fidelity Text-Aware Image Restoration},
      author={Kim, Jin Hyeon and Cho, Paand Kim, Mungyeom and Park, Junghyun and Park, Seohyun and Kim, Jaeyeong and Yi, Jung and Cho, Seokju and Kim, Seungryong},
      journal={arXiv preprint arXiv:2512.02006},
      year={2025}
    }
                </pre>
            </div>
        </div>
    </main>

    <footer class="site-footer">
        <div class="container">
            <p class="credit">Credit: The design of this project page is inspired by previous academic project pages, such as <a href="https://llm-grounded-diffusion.github.io/" target="_blank">LLM-grounded Diffusion</a>, <a href="https://describe-anything.github.io/" target="_blank">Describe-anything</a> and <a href="https://cvlab-kaist.github.io/VIRAL" target="_blank">VIRAL</a>.</p>
        </div>
    </footer>

    <script>
    function toggleMute(element) {
        const video = element.parentElement.querySelector('video');
        const icon = element.querySelector('i');
        const text = element.querySelector('.unmute-text');
        
        if (video.muted) {
            video.muted = false;
            icon.className = 'fa fa-volume-up';
            text.textContent = 'Mute';
        } else {
            video.muted = true;
            icon.className = 'fa fa-volume-off';
            text.textContent = 'Click to unmute';
        }
    }
    
    document.addEventListener('DOMContentLoaded', function() {
        const videos = document.querySelectorAll('video');
        videos.forEach(video => {
            video.addEventListener('play', function() {
                const overlay = this.parentElement.querySelector('.unmute-overlay');
                if (overlay) overlay.style.opacity = '0.8';
            });
            
            video.addEventListener('pause', function() {
                const overlay = this.parentElement.querySelector('.unmute-overlay');
                if (overlay) overlay.style.opacity = '0.8';
            });
        });
        // --- Multi-view Video Sync Logic Start ---
        const slideWrappers = document.querySelectorAll('.slide-video-wrapper');

        slideWrappers.forEach(wrapper => {
            const syncVideos = wrapper.querySelectorAll('video');
            
            if (syncVideos.length === 0) return;

            // Ï≤´ Î≤àÏß∏ ÎπÑÎîîÏò§Î•º ÎßàÏä§ÌÑ∞Î°ú ÏÑ§Ï†ï
            const masterVideo = syncVideos[0];

            const playAll = async () => {
                try {
                    // Î™®Îì† ÎπÑÎîîÏò§ ÏãúÍ∞ÑÏùÑ 0ÏúºÎ°ú Ï¥àÍ∏∞Ìôî
                    syncVideos.forEach(v => v.currentTime = 0);
                    // Î™®Îì† ÎπÑÎîîÏò§ Ïû¨ÏÉù ÏãúÎèÑ
                    const playPromises = Array.from(syncVideos).map(v => v.play());
                    await Promise.all(playPromises);
                } catch (err) {
                    // console.error("Autoplay failed:", err); // ÌïÑÏöîÏãú Ï£ºÏÑù Ìï¥Ï†ú
                }
            };

            // ÎßàÏä§ÌÑ∞ ÎπÑÎîîÏò§Í∞Ä ÎÅùÎÇòÎ©¥ Îã§ Í∞ôÏù¥ Ï≤òÏùåÎ∂ÄÌÑ∞ Îã§Ïãú Ïû¨ÏÉù (Loop ÎèôÍ∏∞Ìôî)
            masterVideo.addEventListener('ended', () => {
                playAll(); 
            });

            // Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Î°úÎìú Ïãú ÏµúÏ¥à 1Ìöå Ïã§Ìñâ
            masterVideo.addEventListener('loadedmetadata', () => {
                 playAll();
            });
        });
        // --- Multi-view Video Sync Logic End ---

        // Initialize all slideshows
        document.querySelectorAll('.slideshow-container').forEach(container => {
            const slideshow = container.querySelector('.slideshow');
            const slides = slideshow.querySelectorAll('.slide');
            const prevButton = container.querySelector('.slideshow-nav.prev');
            const nextButton = container.querySelector('.slideshow-nav.next');
            const playPauseButton = container.querySelector('.play-pause');
            
            let currentSlide = 0;
            let autoplayInterval;
            let isPlaying = true;

            function showSlide(n) {
                slides.forEach(slide => slide.classList.remove('active'));
                currentSlide = (n + slides.length) % slides.length;
                slides[currentSlide].classList.add('active');
            }

            function changeSlide(n) {
                showSlide(currentSlide + n);
                resetAutoplay();
            }

            function togglePlayPause() {
                if (isPlaying) {
                    clearInterval(autoplayInterval);
                    playPauseButton.innerHTML = '<i class="fa fa-play"></i>';
                } else {
                    startAutoplay();
                    playPauseButton.innerHTML = '<i class="fa fa-pause"></i>';
                }
                isPlaying = !isPlaying;
            }

            function startAutoplay() {
                autoplayInterval = setInterval(() => {
                    showSlide(currentSlide + 1);
                }, 5000);
            }

            function resetAutoplay() {
                clearInterval(autoplayInterval);
                if (isPlaying) {
                    startAutoplay();
                }
            }

            // Initialize this slideshow
            showSlide(0);
            startAutoplay();

            // Add event listeners
            prevButton.addEventListener('click', () => changeSlide(-1));
            nextButton.addEventListener('click', () => changeSlide(1));
            playPauseButton.addEventListener('click', togglePlayPause);
        });

        // Handle main video play button
        const mainVideo = document.querySelector('.main-video');
        const playButton = document.querySelector('.play-button-overlay');
        
        if (mainVideo && playButton) {
            // Click play button to play video
            playButton.addEventListener('click', () => {
                mainVideo.play();
                mainVideo.classList.add('playing');
            });

            // Handle video play/pause events
            mainVideo.addEventListener('play', () => {
                mainVideo.classList.add('playing');
            });

            mainVideo.addEventListener('pause', () => {
                mainVideo.classList.remove('playing');
            });

            mainVideo.addEventListener('ended', () => {
                mainVideo.classList.remove('playing');
            });
        }

        // -----------------------------
        // üñºÔ∏è Click-to-zoom Lightbox
        // -----------------------------
        // Build overlay once
        const lightbox = document.createElement('div');
        lightbox.className = 'lightbox-overlay';
        lightbox.setAttribute('role', 'dialog');
        lightbox.setAttribute('aria-modal', 'true');
        lightbox.innerHTML = '<img alt="Expanded image">';
        document.body.appendChild(lightbox);
        const lightboxImg = lightbox.querySelector('img');

        function openLightbox(src, alt) {
            lightboxImg.src = src;
            lightboxImg.alt = alt || '';
            lightbox.classList.add('active');
            document.body.classList.add('no-scroll');
        }
        function closeLightbox() {
            lightbox.classList.remove('active');
            document.body.classList.remove('no-scroll');
            lightboxImg.src = '';
        }

        // Close on click anywhere or on Esc
        lightbox.addEventListener('click', closeLightbox);
        document.addEventListener('keydown', (e) => {
            if (e.key === 'Escape' && lightbox.classList.contains('active')) closeLightbox();
        });

        // Mark target images as zoomable and wire up click
        const zoomableImages = document.querySelectorAll('.image-container img, .slideshow img, .main-content img.img, .hero-section img.img');
        zoomableImages.forEach(img => {
            img.classList.add('zoomable');
            img.addEventListener('click', () => {
                // support optional high-res source via data-fullsrc
                const src = img.getAttribute('data-fullsrc') || img.currentSrc || img.src;
                openLightbox(src, img.alt);
            });
        });
    });
    </script>
</body>
</html>